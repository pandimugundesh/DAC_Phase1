# Data Analytics with Cognos - Group 3(Product Sales Analysis)

Product sales analysis is a fundamental practice that empowers businesses to glean invaluable insights from their sales data. It involves the systematic examination of sales transactions, customer behaviors, and market dynamics to make data-driven decisions that optimize revenue, customer satisfaction, and overall business performance.At its core, product sales analysis is a multifaceted process that delves into the performance of products or services in the market. It offers a comprehensive view of sales metrics such as revenue, units sold, and profit margins, helping businesses to gauge their financial health. By dissecting sales trends, companies can identify seasonality, growth patterns, and fluctuations, enabling them to make informed decisions and forecasts.One of the primary objectives of product sales analysis is to identify top-selling products. This knowledge allows businesses to concentrate their efforts and resources on products with the highest demand, thus maximizing profitability. 

## Key Objectives

This project is designed to achieve the following primary objectives:

1. Identify Top-Selling Products: Determine which products or services are the best performers in terms of sales, revenue, and profit margins.

2. Understand Sales Trends: Analyze historical sales data to identify trends, seasonality, and patterns, helping the business make informed decisions.

3. Optimize Pricing Strategies: Evaluate pricing strategies to ensure products are competitively priced while maintaining healthy profit margins.

4. Enhance Marketing Effectiveness: Assess the effectiveness of marketing campaigns and strategies to allocate resources more efficiently and improve campaign outcomes.

5. Customer Behavior Analysis: Understand customer preferences and behaviors to tailor marketing campaigns, cross-selling, and upselling efforts.

6. Inventory Management: Identify slow-moving or obsolete products to optimize inventory and free up capital and storage space.

7. Forecasting and Planning: Use historical data to make accurate sales forecasts, plan inventory, and prepare for future demand.

8. Competitor Analysis: Compare the business's sales performance with that of competitors to identify opportunities and threats in the market.

9. Profitability Improvement: Identify areas where profitability can be enhanced, such as reducing costs or increasing prices.

10. Data-Driven Decision Making: Promote a data-driven culture within the organization, where decisions are based on factual information rather than assumptions.

11. Customer Satisfaction: Improve customer satisfaction by better understanding customer needs and preferences and aligning products and services accordingly.

12. Market Expansion: Identify opportunities to expand into new markets or target new customer segments.

13. Risk Mitigation: Identify and mitigate risks related to market changes, demand fluctuations, or external factors that could impact sales.

14. Continuous Improvement: Establish a process for ongoing product sales analysis to adapt to changing market conditions and continuously improve performance.

15. Financial Health: Ensure the financial health of the business by closely monitoring sales, revenue, and profit margins.

## Data Sources

The data for this project was collected from various sources with a focus on gathering comprehensive information about sales of a product. The primary data sources and collection methods include:
https://www.kaggle.com/dfsets/anuvagoyal/sales-store-product-details

## Tools and Libraries

The analysis of the socio-economic status of marginal workers in Tamil Nadu was conducted using a combination of tools, programming languages, software, and libraries to ensure a robust and comprehensive analysis. The key tools and resources employed in this project include:

1. **Python:** Python was the primary programming language used for data analysis and statistical calculations. It offers a wide range of data science libraries and is well-suited for data manipulation and visualization.

2. **Pandas:** The Pandas library was instrumental in data preprocessing and manipulation. It allowed us to handle, clean, and transform the dataset efficiently.

3. **Matplotlib and Seaborn:** Matplotlib and Seaborn were used for data visualization, enabling the creation of various charts and graphs to represent key findings from the analysis.

4. **Jupyter Notebooks:** Jupyter Notebooks provided an interactive and collaborative environment for data analysis and documentation. It facilitated the sharing of code, analysis, and visualizations.

5. **Excel:** Microsoft Excel was used for initial data inspection and basic data cleaning. It is a versatile tool for reviewing and structuring datasets.

6. **Qualitative Data Analysis Software:** Qualitative data from in-depth interviews was analyzed using specialized qualitative data analysis software to identify themes and patterns.

7. **Statistical Packages:** Various statistical packages were used for specialized analyses, such as calculating central tendencies, dispersion measures, and regression analysis.

8. **Version Control:** Git and GitHub were employed for version control, allowing for collaboration and tracking changes in the project.

## Data Preprocessing

Data preprocessing is a crucial phase in this project, as it ensures the quality and integrity of the dataset before analysis. The following steps were taken to clean, preprocess, and prepare the data for analysis:

1. **Data Cleaning:** The dataset was inspected for missing values, duplicates, and inconsistencies. Any missing data points were addressed, and duplicate entries were removed to eliminate redundancy. Inconsistencies in data format were standardized to ensure uniformity.

2. **Data Imputation:** Missing values, where possible, were imputed using appropriate techniques. This involved replacing missing numerical values with means or medians and categorical values with modes or using specific imputation strategies.

3. **Outlier Detection and Handling:** Outliers, which can skew the analysis, were identified and evaluated. Depending on the nature of the variable, outliers were either corrected or treated using methods like truncation or transformation.

4. **Data Conversion:** Data types were adjusted as needed. This included converting text data to numerical formats and date-time data to a standardized format. Categorical variables were often encoded for analysis.

5. **Feature Engineering:** New features were created to enhance the dataset's utility. For example, educational levels may have been categorized, and variables were transformed to meet the specific requirements of the analysis.

6. **Data Scaling and Normalization:** Some analyses require that data be on a similar scale or follow a standard distribution. When necessary, data was scaled or normalized to meet these requirements.

7. **Handling Imbalanced Data:** If the dataset exhibited imbalanced classes, techniques such as oversampling, undersampling, or the use of synthetic data were employed to address this issue.

8. **Data Validation:** Data was validated to ensure its integrity and correctness throughout the preprocessing phase.


## Policy Implications

Product sales analysis can have various policy implications for businesses and organizations. These implications can influence decision-making and strategy development. Here are some key policy implications of product sales analysis:

1. **Pricing Policy:**
   - **Dynamic Pricing Strategies:** Sales analysis can reveal optimal pricing strategies. Businesses can adjust pricing dynamically based on demand, competition, and customer behavior.

2. **Inventory Management Policy:**
   - **Inventory Optimization:** Analysis helps identify slow-moving or obsolete products, guiding inventory management policies. Businesses can reduce carrying costs and avoid overstocking.

3. **Marketing Policy:**
   - **Targeted Marketing:** Sales analysis helps identify effective marketing channels and customer segments. Policies can be developed to allocate resources to the most productive marketing efforts.
   - **Campaign Timing:** Knowing sales trends can inform the timing of marketing campaigns, product launches, and promotions.

4. **Product Development and Innovation Policy:**
   - **New Product Development:** Analysis can guide decisions on which types of products or services are in demand, leading to policies for new product development and innovation.
   - **Product Retirement:** Identifying underperforming products can lead to policies for phasing out or retiring certain product lines.

5. **Customer Relations and Service Policies:**
   - **Customer Segmentation:** Segmenting customers based on their preferences and behaviors can inform customer service and engagement policies.
   - **Customer Retention:** Policies can be developed to enhance the customer experience, aiming to increase customer retention and loyalty.

6. **Market Expansion and Diversification Policy:**
   - **Market Entry Decisions:** Sales analysis can help identify opportunities for market expansion. Policies can be established for entering new markets or diversifying products and services.

7. **Competitive Policy:**
   - **Competitive Strategies:** Analysis helps assess how a business performs compared to competitors. Policies can be developed to strengthen competitive strategies.

8. **Policies for Financial Health:**
   - **Profitability Enhancement:** Policies can be formulated to enhance profitability through cost-cutting measures, margin improvement, or financial restructuring.
   - **Risk Mitigation:** Businesses can create policies for risk management based on market analysis, ensuring financial stability in various scenarios.

9. **Data-Driven Decision-Making Policy:**
   - **Promoting a Data-Driven Culture:** Organizations can implement policies to encourage data-driven decision-making, ensuring that analysis is a routine part of operations.

10. **Ethical and Regulatory Policies:**
    - **Data Privacy and Security:** Ensure that policies are in place to protect customer data and comply with data privacy regulations.
    - **Fair Practices:** Develop policies that promote fair business practices, such as pricing transparency and advertising integrity.

11. **Sustainability and Environmental Policies:**
    - **Sustainable Product Strategies:** Use analysis to identify opportunities to develop and market more sustainable products or services.
    - **Reduce Waste:** Policies can be developed to minimize excess production and waste, promoting sustainability.

12. **Employee and Human Resources Policies:**
    - **Resource Allocation:** Based on analysis, organizations can allocate resources for hiring, training, and retaining employees according to sales demands.

13. **Expansion and Growth Policies:**
    - **Capital Allocation:** Policies can be established for allocating capital to support business expansion, whether through physical expansion, mergers, or acquisitions.

14. **Policy for Continuous Improvement:**
    - **Regular Analysis:** Implement policies that ensure that sales analysis is conducted regularly to adapt to changing market conditions and continuously improve performance.

15. **Supply Chain Policies:**
    - **Supply Chain Efficiency:** Policies can be developed to improve the efficiency of the supply chain based on sales data, ensuring products are available when and where they are needed.

These policies are informed by the insights derived from sales analysis, and they guide the strategic decision-making process within an organization. It's crucial for businesses to regularly review and update these policies to stay agile and responsive to market changes.

## Limitations

It is essential to acknowledge the limitations of the analysis, as they provide context for the findings and insights presented. The following limitations should be considered:

1. Data Quality: Data quality is paramount in any analysis. Inaccurate or incomplete data can lead to incorrect conclusions. Data may be outdated, poorly collected, or subject to errors.

2. Data Availability: Availability of relevant data can be a limitation. Some demographic or socioeconomic factors may not be adequately recorded, or data may be challenging to access, especially for specific population groups.

3. Sampling Bias: If the data is collected through surveys or samples, there can be sampling bias. The sample may not fully represent the entire population, leading to skewed results.

4. Causation vs. Correlation: Establishing causal relationships can be difficult. Just because two variables are correlated doesn't mean one causes the other. Correlation does not imply causation.

5. Privacy and Ethical Concerns: Handling personal data can raise privacy and ethical concerns. Ensuring data is anonymized and adheres to ethical guidelines is critical.

6. Data Interpretation: Misinterpretation of data can occur, leading to incorrect conclusions. Ensuring data is analyzed correctly is crucial.

7. Changing Trends: Demographics and socioeconomic factors are not static. They change over time. Analysis might not capture future trends.

8. External Factors: Socioeconomic indicators can be influenced by external factors, such as global events (e.g., economic crises, pandemics) or government policies.

9. Complexity: The analysis can be complex, involving numerous variables and factors. Simplifying this complexity without losing essential information is a challenge.

10. Resource Limitations: Adequate resources, including skilled analysts and appropriate software tools, are necessary for comprehensive analysis. Limited resources can restrict the depth of the analysis.

11. Contextual Factors: The analysis might not always consider specific contextual factors relevant to certain demographic groups or regions.

12. Bias and Stereotyping: Preconceived biases or stereotypes can influence the analysis. It's crucial to approach the analysis with an open mind and strive for objectivity.

13. Interdisciplinary Collaboration: Demographic and socioeconomic analysis often benefits from interdisciplinary collaboration. The lack of input from various fields can limit the scope of the analysis.


## Replication Instructions

To replicate the analysis of the product sales, you can follow these step-by-step instructions using Python as the primary tool:

### Prerequisites

Ensure that you have the following prerequisites installed on your system:

- Python (3.x)
- Jupyter Notebook (optional, but recommended for an interactive experience)

### Step 1: Clone the Repository

You can start by cloning this repository to your local machine using Git:


git clone https://github.com/Prabukl/DAC_Phase1
### Step 2: Install Required Libraries
In your Python environment, install the necessary   
libraries by running the following command:
```shell
pip install pandas matplotlib seaborn os numpy statsmodel
```
### Step 3: Load the Dataset
Load the dataset into your Python environment. Ensure that the dataset file is located in the project folder. You can use the following code to load the dataset into a Pandas DataFrame:
```shell
import pandas as pd

# Load the dataset
data = pd.read_csv('statsfinal.csv')  
```

### Step 4: Data Preprocessing
Perform data preprocessing to clean and prepare the dataset for analysis. Depending on your specific dataset and requirements, this may include handling missing values, data conversion, and outlier detection. Here's a basic example:
```shell
categorical = sales_data.select_dtypes(['category', 'object']).columns
for col in categorical:
    print('{} : {} unique value(s)'.format(col, sales_data[col].nunique()))

```
### Step 5: Data Analysis and Visualization
Analyze the data and create visualizations to obtain insights. Here are examples of how to calculate mean income and create a histogram of age distribution:
```shell
sales_data_numeric = sales_data.describe(include=[np.number])
"Statistical Measure of Sales Data in Numeric Data"
sales_data_numeric
sales_data_object = sales_data.describe(exclude=[np.number])
"Statistical Measure of Sales Data in Object / Str Data"
sales_data_object
def univariate_analysis(data, color, title1, title2):

    fig, (ax1, ax2) = plt.subplots( # subplots
        ncols=2, # num of cols
        nrows=1, # num of rows
        figsize=(20, 6) # set the width and high
    )

    sns.distplot( # create a distplot visualization
        data, # data
        ax=ax1, # axes 1
        kde=True, # kde
        color=color # color
    )

    ax1.set_title( # set the title 1
        title1,
        weight="bold", # weight
        fontsize=25, # font-size
        pad=30 # padding
    )

    qqplot( # qqplot (quantile plot)
        data, # data
        ax=ax2, # axes 2
        line='s' # line
    )

    ax2.set_title( # set the title 2
        title2,
        weight="bold", # weight
        fontsize=25, # font-size
        pad=30 # padding
    )

    return fig # returning the figure
univariate_analysis( # call the function
    data=sales_data['Quantity Ordered'], # put the data
    color='red', # pick the color
    title1='Quantity Ordered Data Distribution', # title1
    title2='Quantile Plot' # title2
);

univariate_analysis( # call the function
    data=sales_data['Price Each'], # put the data
    color='blue', # pick the color
    title1='Price Each Data Distribution', # title1
    title2='Quantile Plot' # title2
);
univariate_analysis( # call the function
    data=sales_data['Sales'], # put the data
    color='black', # pick the color
    title1='Sales Data Distribution', # title1
    title2='Quantile Plot' # title2
);
skew_value = sales_data.skew().sort_values(ascending=False)
skew_value
plt.figure(figsize=(24, 10)) # figuring the size

sns.countplot(
    x="Year",
    data=sales_data
)
plt.title( # title
    "Year Sales and Much Earned in that Year",
    fontname="monospace", # font-name
    weight="bold", # weiqht
    fontsize=35, # font-size
    pad=30 # padding
)
plt.xlabel( # x-label
    "Years",
    weight="bold", # weight
    color="purple", # color
    fontsize=25, # font-size
    loc="center" # location
)
plt.xticks( # x-ticks
    weight="bold", # weight
    fontsize=15 # font-size
)
plt.ylabel( # y-label
    "Sales in USD ($)",
    weight="bold", # weight
    color="green", # color
    fontsize=20 # font-size
)
plt.yticks( # y-ticks
    weight="bold", # weight
    fontsize=15 # font-size
);
sum_of_month_and_earned = sales_data.groupby('Month').sum().astype('int')

plt.figure(figsize=(24, 14)) # figuring the size

sns.barplot( # barplot
    x=sum_of_month_and_earned.index, # x-axis
    y=sum_of_month_and_earned["Sales"], # y-axis
    data=sum_of_month_and_earned, # data
    palette="deep" # palette
)
plt.title( # title
    "Month Sales and Much Earned in that Months",
    fontname="monospace", # font-name
    weight="bold", # weight
    fontsize=35, # font-size
    pad=30 # padding
)
plt.xlabel( # x-label
    "Months",
    weight="bold", # weight
    color="purple", # color
    fontsize=25, # font-size
    loc="center" # location
)
plt.xticks( # x-ticks
    weight="bold", # weight
    fontsize=15 # font-size
)
plt.ylabel( # y-label
    "Sales in USD ($)",
    weight="bold", # weight
    color="green", # color
    fontsize=20 # font-size
)
plt.yticks( # y-ticks
    weight="bold", # weight
    fontsize=15 # font-size
);

```

## Creating Visualizations in IBM Cognos
![image](https://github.com/pandimugundesh/DAC_Phase1/assets/146209549/ddc7ef9f-b4ad-4a78-ac24-05e1a135e3c8)

### Table of Contents

1. **Introduction to IBM Cognos**
   - Brief overview of IBM Cognos and its capabilities.
   - Importance of data visualization in business intelligence.

2. **Prerequisites**
   - What you need to get started with creating visualizations in IBM Cognos.

3. **Step-by-Step Guide**
   - **Logging in to IBM Cognos**
     - Accessing your IBM Cognos environment.

   - **Choosing a Visualization Type**
     - Selecting the right visualization for your data.

   - **Connecting to Data Sources**
     - Linking your visualization to relevant data.

   - **Defining Data Fields**
     - Specifying data columns and parameters.

   - **Customizing Visualizations**
     - Adjusting the appearance of your visualization.

   - **Adding Interaction and Interactivity**
     - Making your visualization more engaging.

   - **Saving and Publishing**
     - Sharing your visualization with others.

   - **Testing and Review**
     - Ensuring the accuracy and effectiveness of your visualization.

   - **Sharing and Collaboration**
     - Collaborating with team members and setting permissions.

   - **Monitoring and Maintenance**
     - Keeping your visualizations up-to-date.

4. **Advanced Tips and Best Practices**
   - Enhance your visualization skills with advanced tips and industry best practices.

5. **Common Challenges and Solutions**
   - Troubleshooting common issues in visualization creation.

### Who Should Use This Guide?

- Data analysts and business professionals seeking to create data visualizations in IBM Cognos.
- Beginners looking to explore the world of data visualization.
- IBM Cognos users interested in improving their visualization skills.
This project was a collaborative effort involving the following team members and contributors:
**Sample**

## Project Contributors

This project was a collaborative effort involving the following team members and contributors:

- **[Prabu K L]** - Project Lead and Data Analyst
- **[Pandi Mugundesh A]** - Data Collection and Preprocessing
- **[Yogeshwaran K]** - Data Visualization and Report Writing
- **[Om Prakash T]** - Qualitative Data Analysis
-  **[Sureendrababu R]** - Quality  Analysis
  
We would like to extend our gratitude to all team members and contributors for their valuable contributions to the successful completion of this project. Their expertise and dedication were instrumental in delivering meaningful insights into product sales
## Project Status

The status of this project is **Completed**. The analysis of Product Sales has been successfully concluded, and the findings and insights have been documented in this repository. The project team has achieved the objectives outlined in the project, and the results are now available for reference and use.


